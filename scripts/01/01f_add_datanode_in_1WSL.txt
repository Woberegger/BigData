# This is used for starting an additional datanode on an existing WSL, where already another datanode is running

# das folgende muss einmalig gemacht werden:
sudo -s 
echo "127.0.0.1 datanode2 datanode3 datanode4" >>/etc/hosts # usw.

# das folgende muss einmalig pro zusätzlichem Datanode gemacht werden:
su - hduser
declare -i DN
DN=2 # für weitere Datanodes diesen Wert verändern
cd $HADOOP_HOME/etc
cp -pR hadoop datanode${DN}
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/datanode${DN}

cat >${HADOOP_CONF_DIR}/hdfs-site.xml <<EOF
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
        <property>
                <name>dfs.replication</name>
                <value>2</value>
        </property>
        <property>
                <name>dfs.permissions</name>
                <value>false</value>
        </property>
        <property>
                <name>dfs.namenode.name.dir</name>
                <value>file:/usr/local/hadoop/hadoopdata/hdfs/namenode</value>
        </property>
        <property>
                <name>dfs.datanode.data.dir</name>
                <value>file:/usr/local/hadoop/hadoopdata/hdfs/datanode${DN}</value>
        </property>
        <property>
                <name>dfs.block.size</name>
                <value>4194304</value>
        </property>
        <property>
          <name>dfs.namenode.accesstime.precision</name>
          <value>3600000</value>
        </property>
        <property>
          <name>dfs.nfs3.dump.dir</name>
          <value>/tmp/.hdfs-nfs</value>
        </property>
        <property>
          <name>dfs.nfs.exports.allowed.hosts</name>
          <value>* rw</value>
        </property>
        <property>
          <name>nfs.metrics.percentiles.intervals</name>
          <value>100</value>
        </property>
        <property>
          <name>nfs.port.monitoring.disabled</name>
          <value>false</value>
        </property>
    <!-- DataNode 2 Konfiguration (neue Ports) -->
    <property>
        <name>dfs.datanode.hostname</name>
        <value>datanode${DN}</value>
    </property>

    <property>
        <name>dfs.datanode.address</name>
        <value>0.0.0.0:5001${DN}</value>
    </property>

    <property>
        <name>dfs.datanode.http.address</name>
        <value>0.0.0.0:5008${DN}</value>
    </property>

    <property>
        <name>dfs.datanode.ipc.address</name>
        <value>0.0.0.0:5002${DN}</value>
    </property>

</configuration>
EOF

sed -i "s#/usr/local/hadoop/hadoopdata/hdfs/tmp#/usr/local/hadoop/hadoopdata/datanode${DN}/tmp#" ${HADOOP_CONF_DIR}/core-site.xml

# das folgende muss dann ausgeführt werden, nachdem der primäre datanode und die sonstigen Prozesse über
# start-dfs.sh (WICHTIG: in einer anderen Session, am besten neue Session als user "hduser") gestartet wurden.

# indem man anderen Wert für Variable DN setzt, kann man das dann für n weitere nodes machen

su - hduser
declare -i DN
DN=2 # für weitere Datanodes diesen Wert verändern
export HADOOP_CONF_DIR=${HADOOP_HOME}/etc/datanode${DN}
# dort wird pid-File mit dem aktuell laufenden Prozess abgelegt - das muss unterschiedlich sein zw. den nodes,
# andernfalls würde das System sagen, dass der Prozess schon läuft
export HADOOP_PID_DIR=/usr/local/hadoop/hadoopdata/datanode${DN}/tmp
# und es sollte auch der Übersichtlichkeit halber eigene Logfiles geben
export HADOOP_LOG_DIR=${HADOOP_HOME}/logs/datanode${DN}
hdfs --daemon start datanode
# zum Stoppen müssen dann dieselben Variablen gesetzt werden, damit die korrekte Instanz des datanodes beendet wird
hdfs --daemon stop datanode

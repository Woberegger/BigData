# Installation von HBase, basierend auf vorheriger Installation von Hadoop
sudo -s
cd /usr/local
export HBASE_VERSION=2.5.10
wget https://dlcdn.apache.org/hbase/${HBASE_VERSION}/hbase-${HBASE_VERSION}-bin.tar.gz
wget https://dlcdn.apache.org/hbase/${HBASE_VERSION}/hbase-${HBASE_VERSION}-bin.tar.gz.sha512
shasum -a 512 hbase-${HBASE_VERSION}-bin.tar.gz; cat hbase-${HBASE_VERSION}-bin.tar.gz.sha512
tar -xzf hbase-${HBASE_VERSION}-bin.tar.gz
chown -R hduser:hadoop /usr/local/hbase-${HBASE_VERSION}
ln -s /usr/local/hbase-${HBASE_VERSION} HBase

# all other actions shall be done as hduser
su - hduser

cat >>~/.bashrc <<!
export HBASE_HOME=/usr/local/HBase
export PATH=\$PATH:\$HBASE_HOME/bin
!

source ~/.bashrc

# Ändern der Dateien $HBASE_HOME/conf/hbase-env.sh und ${HBASE_HOME}/conf/regionservers
# (am besten durch Ausgabeumleitung wie im Folgenden)
cd $HBASE_HOME/conf
export SSH_PORT=10222
#in Datei $HBASE_HOME/conf/hbase-env.sh das JAVA_HOME korrekt setzen, z.B.:
echo "export JAVA_HOME=/usr/lib/jvm/temurin-11-jdk-$(dpkg --print-architecture)" >>${HBASE_HOME}/conf/hbase-env.sh
#im selben File auch den ssh-Port angeben, wenn dieser von 22 abweicht:
echo "export HBASE_SSH_OPTS=\"-p $SSH_PORT -l hduser\"" >>${HBASE_HOME}/conf/hbase-env.sh

# besser auch das Regionserver File konfigurieren, falls später weitere Nodes dazukommen
#export HBASE_REGIONSERVERS=${HBASE_HOME}/conf/regionservers

# hier das eintragen, das man als Hostnamen mit "hdfs getconf -confKey fs.defaultFS | cut -d':' -f2 | cut -c3-" rausbekommt (sollte "namenode" sein)
echo $(hdfs getconf -confKey fs.defaultFS | cut -d':' -f2 | cut -c3-) >${HBASE_HOME}/conf/regionservers

#Sicherungskopie von hbase-site.xml anlegen und dann bearbeiten
cp -p hbase-site.xml hbase-site.xml.orig

#Eventuell für Angabe in hbase-site.xml die URL and Port von HDFS checken (für hbase.rootdir property):
hdfs getconf -confKey fs.defaultFS
 
#Verzeichnis für zookeeper-Daten und logs anlegen (der Ordner "hadoop" gehört ohnehin bereits dem hduser)
mkdir $HADOOP_HOME/zookeeper

# Ändern der Datei $HBASE_HOME/conf/hbase-site.xml (existierende Einträge können gelöscht werden)

   <property>
     <name>hbase.tmp.dir</name>
     <value>./tmp</value>
   </property>
   <property>
     <name>hbase.unsafe.stream.capability.enforce</name>
     <value>false</value>
   </property>
   <property>
      <name>hbase.rootdir</name>
      <value>hdfs://namenode:9000/hbase</value> <!-- Ausgabe von hdfs getconf -confKey fs.defaultFS + "/hbase" -->
   </property>
   <property>
      <name>hbase.zookeeper.property.dataDir</name>
      <!--wie oben mit mkdir angelegt -->
      <value>/usr/local/hadoop/zookeeper</value>
   </property>   
   <property>
     <name>hbase.cluster.distributed</name>
     <value>true</value>
   </property>
   <property>
     <name>hbase.wal.provider</name>
  	  <value>filesystem</value>
   </property>
   
#Testen von HBase
#1.) Hadoop starten
start-dfs.sh
start-yarn.sh

#mit jps testen, ob Hadoop erfolgreich gestartet

#2.) HBase starten
$HBASE_HOME/bin/start-hbase.sh

# möglicherweise gibt es Fehler beim Hochstarten wie folgt:
#a) /usr/local/hadoop/libexec/hadoop-functions.sh: line 2369: HADOOP_ORG.APACHE.HADOOP.HBASE.UTIL.GETJAVAPROPERTY_USER: invalid variable name 
# Lösung: setze Folgendes in hbase-env.sh: export HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP="true"
#b) duplicate implementation von log4j:
# Lösung: Datei $HBASE_HOME/lib/client-facing-thirdparty/log4j-slf4j-impl-2.17.2.jar umbenennen auf log4j-slf4j-impl-2.17.2.jar.duplicate
#c) Fehler mit ssh:
# Lösung in hbase-env.sh: export HBASE_SSH_OPTS="-p 22 -l hduser" # bzw. Port 10222, wenn anderer Port für ssh verwendet wurde
#d) Fehler wie folgt:
# HADOOP_ORG.APACHE.HADOOP.HBASE.UTIL.GETJAVAPROPERTY_USER: invalid variable name
# Lösung: ersetze Datei $HADOOP_HOME/libexec/hadoop-functions.sh durch folgende Version https://github.com/Woberegger/BigData/blob/main/scripts/04/hadoop-functions.sh
#e) Fehler beim Starten oder bei Kommando "hbase classpath"
# Error: Could not find or load main class org.apache.hadoop.hbase.util.GetJavaProperty
# Lösung: ln -s $HBASE_HOME/lib/hbase-server-2.5.6.jar $HADOOP_HOME/share/hadoop/common/
#f) wenn z.B. Prozesse immer schreiben, dass sie jars nicht finden, probier mal den jeweiligen Daemon in der entspr. Reihenfolge lt. start-hbase.sh einzeln zu starten, beginnend mit zookeeper:
# hbase-daemons.sh --config $HBASE_HOME/conf start zookeeper
# danach die Ausgaben in $HBASE_HOME/logs betrachten, ob hier Fehler zu sehen sind

#3.) Prüfen ob HBase Ordner in HDFS angelegt wurden
hdfs dfs -ls /hbase

# andernfall händisch anlegen über
hdfs dfs -mkdir /hbase

# wenn man später mal die Übung von vorne beginnen will, reicht es, folgendes auszuführen:
# stop-hbase.sh; hdfs dfs -rm -R /hbase; rm -Rf $HADOOP_HOME/zookeeper/*

# wenn es Meldung gibt, dass Namenode im save mode ist, dann wie folgt verlassen
hdfs dfsadmin -safemode leave
 
#4.) check status in web browserstatus
"%ProgramFiles%\Google\Chrome\Application\chrome.exe" --new-tab http://localhost:16010/master-status
firefox -new-tab http://localhost:16010/master-status

#5.) HBase Shell öffnen und einfache Tabellen mit Daten anlegen
hbase shell

# Befehl "status" sollte eine Ausgabe wie die folgende liefern
# 1 active master, 0 backup masters, 1 servers, 0 dead, 3.0000 average load

# Inhalt von 04b_HBase_Shell_commands.txt und 04c_HBase_Shell_split_table.txt ausführen
# Cheat Sheet für HBase shell commands z.B. unter https://sparkbyexamples.com/hbase/hbase-shell-commands-cheat-sheet/

#6.) nach dem Anlegen der Tabellen sollten die auch in folgender Web-GUI sichtbar sein
"%ProgramFiles%\Google\Chrome\Application\chrome.exe" --new-tab http://localhost:16010/master-status#userTables
firefox -new-tab http://localhost:16010/master-status#userTables

#################################
Optionen:

#a) weitere Beispiele, z.B. Anzeigen, Zählen oder zum Laden von Daten ausprobieren: Siehe Buch Seiten 202-203,207-209
#   (Achtung: Die Numerierung im pdf ist um Wert 14 höher als die Seitenanzahl im Buch also, geht zu Seite 216 zur Anzeige von Seite 202)
# "Big Data in der Praxis mit Hadoop" BigDataInderPraxis_Auflage1.pdf

# Zum Laden in die Tabelle "peoples" bitte Datei ~/BigData/data/people.csv und script 04d_HBase_import.txt verwenden

# Wenn man gerade beim Datenladen einen Fehler wie den Folgenden bekommt, dann bitte mit "netstat -an | grep 16020" prüfen, ob der Regionserver nicht auf localhost nur lauscht
# Einträge in /etc/hosts und in File "regionservers" kontrollieren.
# Connection refused: <hostname>/<ip>:16020

#b) Wenn man mehrere Regionserver ausprobieren will, muss man auf allen hbase installieren und folgende Datei um die anderen Server erweitern (und hbase services neu starten)
$HBASE_HOME/conf/regionservers

# Dazu muss man jedoch hbase auf allen Nodes installieren und dort folgendes ausführen
$HBASE_HOME/bin/hbase-daemon.sh --config $HBASE_HOME/conf start regionserver

#c) Hbase analog zu HDFS in Autostart reinhängen und ebenso stoppen beim Runterfahren der VM (systemctl Script unter /etc/systemd/system anlegen)
# siehe z.B. Anleitung unter https://blog.hartinger.net/ubuntu-server-autostart-eines-commands-einrichten/
#wichtig: Zur Sicherheit vorher Snapshot der virtuellen Maschine erstellen!

sudo -s
cd /usr/local
wget https://dlcdn.apache.org/hbase/2.5.6/hbase-2.5.6-bin.tar.gz
wget https://dlcdn.apache.org/hbase/2.5.6/hbase-2.5.6-bin.tar.gz.sha512
shasum -a 512 hbase-2.5.6-bin.tar.gz; cat hbase-2.5.6-bin.tar.gz.sha512
tar -xzvf hbase-2.5.6-bin.tar.gz
chown -R hduser:hadoop /usr/local/hbase-2.5.6 
ln -s /usr/local/hbase-2.5.6 HBase

# all other actions shall be done as hduser
su - hduser

cat >>~/.bashrc <<!
export HBASE_HOME=/usr/local/HBase
export PATH=\$PATH:\$HBASE_HOME/bin
# maybe we need this for HBase Java programs
#export HADOOP_CLASSPATH=\$HBASE_HOME/lib:\$HBASE_HOME/lib/client-facing-thirdparty
!

source ~/.bashrc

# Ändern der Datei $HBASE_HOME/conf/hbase-env.sh
cd $HBASE_HOME/conf
#in Datei $HBASE_HOME/conf/hbase-env.sh das JAVA_HOME korrekt setzen, z.B.:
#JAVA_HOME=/usr/lib/jvm/jdk
# besser auch das Regionserver File konfigurieren, falls später weitere Nodes dazukommen
#export HBASE_REGIONSERVERS=${HBASE_HOME}/conf/regionservers

#Sicherungskopie von hbase-site.xml anlegen und dann bearbeiten
# Frage: was macht das "-p" Flag?
cp -p hbase-site.xml hbase-site.xml.orig

#Eventuell für Angabe in hbase-site.xml die URL and Port von HDFS checken (für hbase.rootdir property):
hdfs getconf -confKey fs.defaultFS
 
#Verzeichnis für zookeeper-Daten und logs anlegen (der Ordner "hadoop" gehört ohnehin bereits dem hduser)
mkdir /usr/local/hadoop/zookeeper

# Ändern der Datei $HBASE_HOME/conf/hbase-site.xml

   <property>
     <name>hbase.tmp.dir</name>
     <value>./tmp</value>
   </property>
   <property>
     <name>hbase.unsafe.stream.capability.enforce</name>
     <value>false</value>
   </property>
   <property>
      <name>hbase.rootdir</name>
      <value>hdfs://namenode:9000/hbase</value> <!-- Ausgabe von hdfs getconf -confKey fs.defaultFS -->
   </property>
	
   <property>
      <name>hbase.zookeeper.property.dataDir</name>
      <!--wie oben mit mkdir angelegt -->
      <value>/usr/local/hadoop/zookeeper</value>
   </property>
   
   <property>
     <name>hbase.cluster.distributed</name>
     <value>true</value>
   </property>

   <property>
     <name>hbase.wal.provider</name>
  	  <value>filesystem</value>
   </property>
   
#Testen von HBase
#1.) Hadoop starten
start-dfs.sh
start-yarn.sh

#mit jps testen, ob Hadoop erfolgreich gestartet

#2.) HBase starten
$HBASE_HOME/bin/start-hbase.sh

# möglicherweise gibt es Fehler beim Hochstarten wie folgt:
#a) /usr/local/hadoop/libexec/hadoop-functions.sh: line 2369: HADOOP_ORG.APACHE.HADOOP.HBASE.UTIL.GETJAVAPROPERTY_USER: invalid variable name 
# Lösung: setze Folgendes in hbase-env.sh: export HBASE_DISABLE_HADOOP_CLASSPATH_LOOKUP="true"
#b) duplicate implementation von log4j:
# Lösung: Datei $HBASE_HOME/lib/client-facing-thirdparty/log4j-slf4j-impl-2.17.2.jar umbenennen auf log4j-slf4j-impl-2.17.2.jar.duplicate
#c) Fehler mit ssh:
# Lösung in hbase-env.sh: export HBASE_SSH_OPTS="-p 22 -l hduser"
#d) Fehler wie folgt:
# HADOOP_ORG.APACHE.HADOOP.HBASE.UTIL.GETJAVAPROPERTY_USER: invalid variable name
# Lösung: ersetze Datei $HADOOP_HOME/libexec/hadoop-functions.sh durch folgende Version https://github.com/Woberegger/BigData/blob/main/scripts/04/hadoop-functions.sh


#3.) Prüfen ob HBase Ordner in HDFS angelegt wurden
hdfs dfs -ls /hbase

# andernfall händisch anlegen über
hdfs dfs -mkdir /hbase

# wenn man später mal die Übung von vorne beginnen will, reicht es, folgendes auszuführen:
# hdfs dfs -rm -R /hbase

# wenn es Meldung gibt, dass Namenode im save mode ist, dann wie folgt verlassen
hdfs dfsadmin -safemode leave
 
#4.) check status in web browserstatus
firefox -new-tab http://localhost:16010/master-status

#5.) HBase Shell öffnen und einfache Tabellen mit Daten anlegen
hbase shell

# Befehl "status" sollte eine Ausgabe wie die folgende liefern
# 1 active master, 0 backup masters, 1 servers, 0 dead, 3.0000 average load

# Inhalt von 04_HBase_Shell_commands.txt und 04_HBase_Shell_split_table.txt ausführen
# Cheat Sheet für HBase shell commands z.B. unter https://sparkbyexamples.com/hbase/hbase-shell-commands-cheat-sheet/

#6.) nach dem Anlegen der Tabellen sollten die auch in folgender Web-GUI sichtbar sein

firefox -new-tab http://localhost:16010/master-status#userTables

#################################
Optionen:

#a) weitere Beispiele, z.B. Anzeigen, Zählen oder zum Laden von Daten ausprobieren: Siehe Buch Seiten 202-203,207-209
#   (Achtung: Die Numerierung im pdf ist um Wert 14 höher als die Seitenanzahl im Buch also, geht zu Seite 216 zur Anzeige von Seite 202)
https://elearning.fh-joanneum.at/pluginfile.php/96582/mod_resource/content/1/BigDataInderPraxis_Auflage1.pdf

# Zum Laden in die Tabelle "peoples" bitte Datei https://github.com/Woberegger/BigData/blob/main/data/people.csv und script 04_HBase_import.txt verwenden

# Wenn man gerade beim Datenladen einen Fehler wie den Folgenden bekommt, dann bitte mit "netstat -an | grep 16020" prüfen, ob der Regionserver nicht auf localhost nur lauscht
# Einträge in /etc/hosts und in File "regionservers" kontrollieren.
# Connection refused: <hostname>/<ip>:16020

#b) Wenn man mehrere Regionserver ausprobieren will, muss man auf allen hbase installieren und folgende Datei um die anderen Server erweitern (und hbase services neu starten)
$HBASE_HOME/conf/regionservers

# Dazu muss man jedoch hbase auf allen Nodes installieren und dort folgendes ausführen
$HBASE_HOME/bin/hbase-daemon.sh --config $HBASE_HOME/conf start regionserver

#c) Hbase analog zu HDFS in Autostart reinhängen und ebenso stoppen beim Runterfahren der VM (systemctl Script unter /etc/systemd/system anlegen)
# siehe z.B. Anleitung unter https://blog.hartinger.net/ubuntu-server-autostart-eines-commands-einrichten/